## Snakemake - sRNA_pipeline
##
## @RAVEL-Sebastien
##

import glob
import re, sys
from pathlib import Path
from script.module import getLibarySize, mergeCSV, filterBam, plotGraph, mergeImages

from snakemake.utils import validate

# validate(config, "schema.json")

# exit(1)

###############################################################################
# NOTE pas de caractere speciaux entre 2 wildcards

# --- Importing Configuration Files --- #
configfile: 'config.yaml'

# dir and suffix
samples_dir = config["DATA"]["directories"]["samples_dir"]
references_dir =  config["DATA"]["directories"]["references_dir"]
out_dir = config["DATA"]["directories"]["out_dir"]
suffixFile = config["DATA"]["fasta_suffix"]

# pipeline options
plotOption = config["PIPE_OPTION"]["plotOption"]
size_min = config["PIPE_OPTION"]["size_min"]
size_max = config["PIPE_OPTION"]["size_max"]

# to lunch separator
sep="#"

#*###############################################################################
def finalReturn(wildcards):
	if plotOption:
		toto = expand(out_dir+'6_plot_graph_merge/{samples}_{references}_merge.png', samples = SAMPLES, references = REFERENCES)
		toto.append(out_dir+'4_merges_resume_files/all_Resume.csv')
		return toto
	else:
		return [out_dir+'4_merges_resume_files/all_Resume.csv']

#*###############################################################################
for path in ["0_mapping_sRNA","1_csv_size_lib", "2_merge_bam_sRNA", "3_bam_filter","4_merges_resume_files","5_plot_graph", "6_plot_graph_merge"]:
	Path(f"{out_dir}/LOG/{path}/").resolve().mkdir(parents=True, exist_ok=True)

#*###############################################################################
SAMPLES,FASTQ2 = glob_wildcards(samples_dir+"{samples}/{fastq}.fastq", followlinks=True)
FASTQ, = glob_wildcards(samples_dir+"{fastq}.fastq", followlinks=True)
REFERENCES, = glob_wildcards(references_dir+"{references}."+suffixFile, followlinks=True)
SAMPLES = list(set(SAMPLES))





# --- Main Build Rules --- #

rule final:
	"""construct a table of all resume files"""
	input:
		finalReturn


rule bwaIndex:
	"""make index with bwa for all reference files"""
	threads: 1
	input: 	fasta = references_dir+"{references}."+suffixFile
	params: l_mem_free='4G',
			queue="normal.q",
			errorLog = out_dir+'LOG/0_mapping_sRNA/{references}_bwaindex.e',
			outputLog = out_dir+'LOG/0_mapping_sRNA/{references}_bwaindex.o'
	output: sa_file = references_dir+"{references}."+suffixFile+".sa"
	message: """Execute BWA INDEX for {wildcards.references}
		Input:
			- Fasta : {input.fasta}
			- Threads : {threads}
			"""+f"\n{sep*108}"
	shell: config["MODULES"]["BWA"]+"""
		bwa index {input.fasta}
	"""

rule bwaAln:
	"""make bwa aln for all samples on all references"""
	threads: 4
	input: 	fasta = references_dir+"{references}."+suffixFile,
			index = references_dir+"{references}."+suffixFile+".sa",
			fastq = samples_dir+'{fastq}.fastq'
	params: l_mem_free='4G',
			queue="normal.q",
			errorLog = out_dir+'LOG/0_mapping_sRNA/{references}_bwaaln.e',
			outputLog = out_dir+'LOG/0_mapping_sRNA/{references}_bwaaln.o'
	output: sai_file = out_dir+'0_mapping_sRNA/{references}-ref/{fastq}.sai'
	message: """Execute BWA ALN for {wildcards.fastq}
		Input:
			- Fasta : {input.fasta}
			- Fastq : {input.fastq}
			- Threads : {threads}"""+f"\n{sep*108}"
	shell: config["MODULES"]["BWA"]+"""
		bwa aln -t {threads} -n 2 -f {output.sai_file} {input.fasta} {input.fastq}
	"""

rule bwaSamse:
	"""make bwa samse for all samples on all references"""
	threads: 1
	input: 	fasta = references_dir+"{references}."+suffixFile,
			fastq = samples_dir+'{fastq}.fastq',
			index = references_dir+"{references}."+suffixFile+".sa",
			sai_file = out_dir+'0_mapping_sRNA/{references}-ref/{fastq}.sai'
	params: l_mem_free='4G',
			queue="normal.q",
			errorLog = out_dir+'LOG/0_mapping_sRNA/{references}_bwasamse.e',
			outputLog = out_dir+'LOG/0_mapping_sRNA/{references}_bwasamse.o',
	output: sam_file = out_dir+'0_mapping_sRNA/{references}-ref/{fastq}.sam'
	message: """Execute BWA SAMSE for {wildcards.fastq}
		Input:
			- Fasta : {input.fasta}
			- Fastq : {input.fastq}
			- Threads : {threads}"""+f"\n{sep*108}"
	shell: config["MODULES"]["BWA"]+"""
		fastqfile="{input.fastq}"
		readgroupsF=$(basename ${{fastqfile%%.fastq}})
		readgroups=${{readgroupsF%%_*}}
		bwa samse -f {output.sam_file} -r"@RG\tID:${{readgroups}}\tSM:${{readgroups}}\tPL:Illumina" {input.fasta} {input.sai_file} {input.fastq}
	"""


rule samtoolsfilter:
	"""make samtools view to remove non-mapping, and samtools sort for all samples on all references"""
	threads: 4
	input: 	sam_file = out_dir+'0_mapping_sRNA/{references}-ref/{fastq}.sam'
	params: l_mem_free='4G',
			queue="normal.q",
			errorLog = out_dir+'LOG/0_mapping_sRNA/{references}_samtoolsFilter.e',
			outputLog = out_dir+'LOG/0_mapping_sRNA/{references}_samtoolsFilter.o',
	output: bam_file = out_dir+'0_mapping_sRNA/{references}-ref/{fastq}_sorted.bam'
	message: """Execute SAMTOOLS VIEW AND SORT for {wildcards.fastq}
		Input:
			- SAM : {input.sam_file}
			- Threads : {threads}"""+f"\n{sep*108}"
	shell: config["MODULES"]["SAMTOOLS"]+"""
		samtools view -@ {threads} -F 4 -b  -h {input.sam_file} | samtools sort -@ {threads} -o {output.bam_file}
	"""

rule samtoolsMerge:
	"""make samtools merge for all samples size to one on all references"""
	threads: 4
	input: 	lien = expand(out_dir+'0_mapping_sRNA/{references}-ref/{fastq}_sorted.bam', fastq = FASTQ, references = REFERENCES),
	params: l_mem_free='4G',
			queue="normal.q",
			errorLog = out_dir+'LOG/2_merge_bam_sRNA/{references}_sammtoolsMerge.e',
			outputLog = out_dir+'LOG/2_merge_bam_sRNA/{references}_sammtoolsMerge.o',
			bam_files = out_dir+'0_mapping_sRNA/{references}-ref/{samples}/'
	output: bam_file = out_dir+'2_merge_bam_sRNA/{references}-ref/{samples}/{samples}_merge.bam'
	message: """Execute SAMTOOLS MERGE for {wildcards.samples}
		Input:
			- BAM files : {params.bam_files}
			- Threads : {threads}"""+f"\n{sep*108}"
	shell: config["MODULES"]["SAMTOOLS"]+"""
		ls {params.bam_files}*_sorted.bam > {params.bam_files}bamList
		samtools merge -@ {threads} -b {params.bam_files}bamList {output.bam_file}
	"""


rule getLibarySizesRNA:
	"""calculate library size for all samples"""
	threads: 1
	input: sRNA = samples_dir+"{samples}/"
	params: l_mem_free='4G',
			size_min = size_min,
			size_max = size_max,
			queue="normal.q",
			errorLog = out_dir+'LOG/1_csv_size_lib/{samples}_getLibarySizesRNA.e',
			outputLog = out_dir+'LOG/1_csv_size_lib/{samples}_getLibarySizesRNA.o'
	output: csv_file = out_dir+'1_csv_size_lib/{samples}.csv',
	message: """Execute getLibarySizesRNA for {wildcards.samples}
		Input:
			- Sample files : {input.sRNA}
			- Threads : {threads}"""+f"\n{sep*108}"
	run:
		getLibarySize(input.sRNA, params.size_min, params.size_max, output.csv_file)

rule mergeCSVfiles:
	"""merge all samples library size into unique file"""
	threads: 1
	input: csv_files = expand(out_dir+'1_csv_size_lib/{samples}.csv', samples = SAMPLES)
	params: l_mem_free='4G',
			queue="normal.q",
			errorLog = out_dir+'LOG/1_csv_size_lib/mergeCSVfiles.e',
			outputLog = out_dir+'LOG/1_csv_size_lib/mergeCSVfiles.o'
	output: csv_file = report(out_dir+'1_csv_size_lib/mergeAllSamples.csv', category="Library size")
	message:"""Execute mergeCSVfiles for {wildcards.samples}
		Input:
			- Sample files : {input.csv_files}
			- Threads : {threads}"""+f"\n{sep*108}"
	run:
		mergeCSV(input.csv_files, output.csv_file)

rule filterBAMFiles:
	"""filter samples bam to keep only size on params"""
	threads: 1
	input: bam_file = out_dir+'2_merge_bam_sRNA/{references}-ref/{samples}/{samples}_merge.bam'
	params: l_mem_free='4G',
			size_min = size_min,
			size_max = size_max,
			queue="normal.q",
			sample_name = "{samples}",
			errorLog = out_dir+'LOG/3_bam_filter/{references}_{samples}_filterBAMFiles.e',
			outputLog = out_dir+'LOG/3_bam_filter/{references}_{samples}_filterBAMFiles.o'
	output: bam_filter_file = out_dir+'3_bam_filter/{samples}/{references}/{samples}_{references}_filter'+str(size_min)+'-'+str(size_max)+'.bam'
	message: """Execute filterBAMFiles for {wildcards.samples}
		Input:
		- Bam: {input.bam_file}
		- Size_min:{params.size_min}
		- Size_max:{params.size_max}
		- Threads : {threads}"""+f"\n{sep*108}"
	run:
		filterBam(input.bam_file, params.size_min, params.size_max, output.bam_filter_file, params.sample_name)


if plotOption:
	output_list = [out_dir+'3_bam_filter/{samples}/{references}/{samples}_{references}_Resume.csv',
					out_dir+'3_bam_filter/{samples}/{references}/{samples}_{references}_table_pm_20-25_normalised.csv'
					]
else:
	output_list = [out_dir+'3_bam_filter/{samples}/{references}/{samples}_{references}_Resume.csv']

rule countOnBAM:
	"""read bam file to extract infos for all samples"""
	threads : 1
	input : bam_file = out_dir+'2_merge_bam_sRNA/{references}-ref/{samples}/{samples}_merge.bam',
			bam_filter_file = out_dir+'3_bam_filter/{samples}/{references}/{samples}_{references}_filter'+str(size_min)+'-'+str(size_max)+'.bam',
			csv_file = out_dir+'1_csv_size_lib/mergeAllSamples.csv'
	params : l_mem_free='10G',
			size_min = size_min,
			size_max = size_max,
			queue="normal.q",
			errorLog = out_dir+'LOG/3_bam_filter/{references}_{samples}_countOnBAM.e',
			outputLog = out_dir+'LOG/3_bam_filter/{references}_{samples}_countOnBAM.o',
			plot = "" if plotOption else "-t"
	output : output_list
	message: """Execute countOnBAM for {wildcards.samples}
		Input:
		- Bam: {input.bam_filter_file}
		- Size_min:{params.size_min}
		- Size_max:{params.size_max}
		- Threads : {threads}"""+f"\n{sep*108}"
	shell : config["MODULES"]["PYTHON3"]+"""
	python3 script/countFromBamNormalize.py -s {params.size_min} {params.size_max} {params.plot} -bf {input.bam_filter_file} -ba {input.bam_file} -l {input.csv_file}
	"""

rule mergeResume:
	"""merge all resume files"""
	threads : 1
	input : csv_resume = expand(rules.countOnBAM.output[0] , samples = SAMPLES, references = REFERENCES),
	params : l_mem_free='4G',
			queue="normal.q",
			errorLog = out_dir+'LOG/4_merges_resume_files/mergeResume.e',
			outputLog = out_dir+'LOG/4_merges_resume_files/mergeResume.o'
	output : #csv_resume_merge = out_dir+'4_merges_resume_files/all_Resume.csv',
			csv_resume_merge = report(out_dir+'4_merges_resume_files/all_Resume.csv', category="Resume stats infos")
	message: """Execute mergeResume for all samples
		Input:
		- CSV: {input.csv_resume}
		- Threads : {threads}"""+f"\n{sep*108}"
	run :
		mergeCSV(input.csv_resume, output.csv_resume_merge, sep="\t")

if plotOption:
	rule plotBarPlot:
		"""Plot the graph"""
		threads : 1
		input : csv_normalize = rules.countOnBAM.output[1]
		params : l_mem_free='10G',
				queue="short.q",
				errorLog = out_dir+'LOG/5_plot_graph/{references}_{samples}_plot.e',
				outputLog = out_dir+'LOG/5_plot_graph/{references}_{samples}_plot.o',
				sample_name = '{samples}',
				reference_name = '{references}',
		output : # png_file = report(out_dir+'5_plot_graph/{samples}_{references}_no-scale.png', category="Plot infos")
				 png_file = out_dir+'5_plot_graph/{samples}_{references}_no-scale.png'
		message: """Execute plotBarPlot for {wildcards.samples}
			Input:
			- CSV: {input.csv_normalize}
			- Threads : {threads}"""+f"\n{sep*108}"
		run :
			plotGraph(csv_file_name = input.csv_normalize, sample_name = params.sample_name, reference_name = params.reference_name, out_file_name = output.png_file)

	rule plotBarPlotScale:
		"""Plot the graph"""
		threads : 1
		input : csv_normalize = rules.countOnBAM.output[1]
		params : l_mem_free='10G',
				queue="short.q",
				errorLog = out_dir+'LOG/5_plot_graph/{references}_{samples}_plotscale.e',
				outputLog = out_dir+'LOG/5_plot_graph/{references}_{samples}_plotscale.o',
				sample_name = '{samples}',
				reference_name = '{references}',
		output : # png_file = report(out_dir+'5_plot_graph/{samples}_{references}_scale.png', category="Plot Scale infos")
				png_file = out_dir+'5_plot_graph/{samples}_{references}_scale.png'
		message: """Execute plotBarPlotScale for {wildcards.samples}
			Input:
			- CSV: {input.csv_normalize}
			- jobid {jobid}
			- Threads : {threads}"""+f"\n{sep*108}"
		run :
			plotGraph(csv_file_name = input.csv_normalize, sample_name = params.sample_name, reference_name = params.reference_name, out_file_name = output.png_file, same_y_scale = True)

	rule mergePlot:
		"""Plot the graph"""
		threads : 1
		input : img1 = out_dir+'5_plot_graph/{samples}_{references}_no-scale.png',
				img2 = out_dir+'5_plot_graph/{samples}_{references}_scale.png',
		params : l_mem_free='4G',
				queue="short.q",
				errorLog = out_dir+'LOG/6_plot_graph_merge/{references}_{samples}_plotMerge.e',
				outputLog = out_dir+'LOG/6_plot_graph_merge/{references}_{samples}_plotMerge.o',
				sample_name = '{samples}',
				reference_name = '{references}'
		output : png_file = report(out_dir+'6_plot_graph_merge/{samples}_{references}_merge.png', category="Plot Merge infos")
		message: """Execute mergePlot for {wildcards.samples}
			Input:
			- image1: {input.img1}
			- image2: {input.img2}
			- jobid {jobid}
			- Threads : {threads}"""+f"\n{sep*108}"
		run :
			# os.system(shell_prefix)
			mergeImages(img1 = input.img1, img2 = input.img2, output_name = output.png_file)



# --- Clean Rules --- #
rule clean:
	"""clean mapping folder"""
	params:
		to_clean =  out_dir+'0_mapping_sRNA/'
	message: 'All good, cleanning mapping files:{params.to_clean}'
	shell:"""
		rm -rf {params.to_clean}
	"""

# --- Help Rules --- #
rule help:
	"""prints help comments for Snakefile"""
	input: "sRNA_pipeline.snake"
	shell:
		# print(docstring)
		"snakemake -lt -s {input}"


# rule mapping_sRNA_TOOGLe :
	# threads: 1
	# input: 	fasta = references_dir+"{references}"+suffixFile,
			# sRNA = samples_dir+"{samples}/", config = configFile
	# params: l_mem_free='4G',
			# queue="normal.q",
			# bam_Dir = directory(out_dir+'0_mapping_sRNA/{references}/{samples}/'),
			# errorLog = out_dir+'LOG/0_mapping_sRNA/{references}_{samples}_mapping_sRNA_TOOGLe.e',
			# outputLog = out_dir+'LOG/0_mapping_sRNA/{references}_{samples}_mapping_sRNA_TOOGLe.o'
	# output: bam_file = out_dir+'0_mapping_sRNA/{references}/{samples}/finalResults/intermediateResults.SAMTOOLSMERGE.bam'
	# message: 'Executing mapping_sRNA_TOOGLe'
	# shell:"""
		# module purge; module load bioinfo/TOGGLE/0.3.7
		# rm -r {params.bam_Dir}
		# toggleGenerator.pl -d {input.sRNA} -r {input.fasta} -c {input.config} -o {params.bam_Dir} -nocheck
	# """

# rule report:
	# input: csv_resume_merge = out_dir+'4_merges_resume_files/all_Resume.csv',
			# csv_file = out_dir+'1_csv_size_lib/mergeAllSamples.csv'
	# params:	errorLog = out_dir+'LOG/report.e',
			# outputLog = out_dir+'LOG/report.o',
			# l_mem_free='4G',
			# queue="short.q"
	# output: html=out_dir+"report.html"
	# run:
		# from snakemake.utils import report
		# report("""
		# ============================
		# sRNA Pipeline version report
		# ============================

		# :author: Sebastien Ravel
		# :contact: sebastien.ravel@cirad.fr
		# :date: 08/11/2016
		# :version: 0.1

		# Workflow run with all these parameters:

		# * Samples directory: {samples_dir}
		# * References directory: {references_dir}
		# * Output directory: {out_dir}
		# * TOGGLe configuration file: {configFile}
		# * Size keep: {size_min} to {size_max}

		# Output files:

		# * CSV file with all the library size for {size_min} to {size_max}: csv_file__
		# * CSV file with all the resume individual file: csv_resume_merge__

		# -------------------------------------------------
		# """, output.html, metadata="Sébastien RAVEL (sebastien.ravel@cirad.fr)", **input)



################################################################################
